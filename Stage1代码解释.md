# SeqKDè®­ç»ƒæµç¨‹è¯¦è§£

## ä¸€ã€æ¦‚è¿°

**SeqKD (Sequence Knowledge Distillation)** æ˜¯GADè®­ç»ƒçš„ç¬¬ä¸€é˜¶æ®µï¼Œä½œä¸ºbaselineã€‚å®ƒä½¿ç”¨GRPOæ¡†æ¶çš„åŸºç¡€è®¾æ–½ï¼Œä½†å®é™…é‡‡ç”¨SFTç­–ç•¥è®­ç»ƒã€‚

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š
- ç”Ÿæˆå¤šä¸ªå“åº”ç”¨äºç›‘æ§ï¼Œä½†è®­ç»ƒæ—¶åªä½¿ç”¨teacherå“åº”
- ä¸ºåç»­çš„å¯¹æŠ—è®­ç»ƒå‡†å¤‡åŸºç¡€è®¾æ–½
- é€šè¿‡Rouge-Lè¯„ä¼°ç”Ÿæˆè´¨é‡

## äºŒã€è®­ç»ƒæµç¨‹å›¾

```mermaid
graph TD
    A[åŠ è½½è®­ç»ƒæ•°æ®] --> B[ç”Ÿæˆ8ä¸ªå“åº”<br/>VLLMæ¨ç†]
    B --> C[è®¡ç®—Rouge-Låˆ†æ•°<br/>ä»…ç”¨äºç›‘æ§]
    C --> D[æ•°æ®æ‰©å±•<br/>repeat n=8æ¬¡]
    D --> E[é€‰æ‹©teacheræ•°æ®<br/>ä¸¢å¼ƒ8ä¸ªé‡‡æ ·]
    E --> F[SFTè®­ç»ƒ<br/>æœ€å¤§åŒ–teacherä¼¼ç„¶]
    F --> G[ä¿å­˜checkpoint]
    G --> H{æ˜¯å¦å®Œæˆ?}
    H -->|å¦| A
    H -->|æ˜¯| I[è¿›å…¥Warmupé˜¶æ®µ]
```

## ä¸‰ã€å…³é”®é˜¶æ®µè¯¦è§£

### é˜¶æ®µ1: æ•°æ®å‡†å¤‡ä¸ç”Ÿæˆ

```
è¾“å…¥æ•°æ®ç»“æ„ï¼š
â”œâ”€â”€ prompts: [p1, p2, ..., p32]              # 32ä¸ªé—®é¢˜
â””â”€â”€ teacher_response: [t1, t2, ..., t32]     # GPT-5çš„å“åº”
```

**å…³é”®å‡½æ•°**ï¼š[actor_rollout_wg.generate_sequences()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/fsdp_workers.py:1770:4-1850:27)

**ä½œç”¨**ï¼šä½¿ç”¨VLLMå¼•æ“ä¸ºæ¯ä¸ªpromptç”Ÿæˆn=8ä¸ªä¸åŒå“åº”

**è¾“å‡º**ï¼š
```
ç”Ÿæˆç»“æœï¼š
â”œâ”€â”€ prompts: [p1]*8 + [p2]*8 + ... (256ä¸ª)
â”œâ”€â”€ responses: [p1_r1, p1_r2, ..., p1_r8, ...] (256ä¸ªé‡‡æ ·)
â””â”€â”€ teacher_response: [t1]*8 + [t2]*8 + ... (256ä¸ª)
```

### é˜¶æ®µ2: è´¨é‡è¯„ä¼°ï¼ˆä»…éªŒè¯é˜¶æ®µï¼‰

**å…³é”®å‡½æ•°**ï¼š`rouge_scorer.RougeScorer.score()`

**ä½œç”¨**ï¼šè®¡ç®—ç”Ÿæˆå“åº”ä¸teacherçš„ç›¸ä¼¼åº¦

**è®¡ç®—å…¬å¼**ï¼š
```
Rouge-L = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
å…¶ä¸­ï¼š
- Precision = LCSé•¿åº¦ / ç”Ÿæˆå“åº”é•¿åº¦
- Recall = LCSé•¿åº¦ / teacheré•¿åº¦
- LCS = æœ€é•¿å…¬å…±å­åºåˆ—
```

**ç”¨é€”**ï¼š
- âœ… éªŒè¯é˜¶æ®µï¼šè¯„ä¼°æ¨¡å‹è´¨é‡
- âœ… æ—¥å¿—è®°å½•ï¼šç›‘æ§è®­ç»ƒè¿›åº¦
- âŒ è®­ç»ƒé˜¶æ®µï¼šä¸å‚ä¸æ¢¯åº¦è®¡ç®—

### é˜¶æ®µ3: æ•°æ®é€‰æ‹©ï¼ˆæ ¸å¿ƒå·®å¼‚ï¼‰

**å…³é”®ä»£ç ä½ç½®**ï¼š[dp_actor.py::update_policy()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/actor/dp_actor.py:387:4-513:22)

**æ•°æ®ç­›é€‰**ï¼š
```python
select_keys = [
    "teacher_response",        # â† åªä¿ç•™è¿™äº›
    "teacher_input_ids",
    "teacher_attention_mask",
    "teacher_position_ids"
]
# æ³¨æ„ï¼šresponsesï¼ˆ8ä¸ªé‡‡æ ·ï¼‰è¢«ä¸¢å¼ƒ
```

**æ•°æ®æµè½¬æ¢**ï¼š
```
è®­ç»ƒå‰ï¼š256ä¸ªæ ·æœ¬ï¼ˆ32 prompts Ã— 8 responsesï¼‰
         â†“ é€‰æ‹©teacherç›¸å…³å­—æ®µ
è®­ç»ƒæ—¶ï¼š256ä¸ªteacheræ ·æœ¬ï¼ˆå…¨éƒ¨æ˜¯teacher_responseï¼‰
```

### é˜¶æ®µ4: SFTè®­ç»ƒ

**å…³é”®å‡½æ•°**ï¼š[compute_sft_loss()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/core_algos.py:634:0-641:18)

**æŸå¤±è®¡ç®—**ï¼š
```
Loss = -mean(log P(teacher_token | context))
```

**è®­ç»ƒç›®æ ‡**ï¼šæœ€å¤§åŒ–æ¨¡å‹ç”Ÿæˆteacherå“åº”çš„æ¦‚ç‡

**ä¼˜åŒ–è¿‡ç¨‹**ï¼š
```
1. å‰å‘ä¼ æ’­ï¼šmodel(teacher_input_ids) â†’ logits
2. è®¡ç®—log_probï¼šlog P(teacher_response)
3. è®¡ç®—æŸå¤±ï¼š-mean(log_prob)
4. åå‘ä¼ æ’­ï¼šæ›´æ–°æ¨¡å‹å‚æ•°
5. æ¢¯åº¦è£å‰ªï¼šclip_grad_norm_(max_norm=0.2)
```

## å››ã€å…³é”®å‡½æ•°è¯´æ˜

### 1. [RayPPOTrainer.fit()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/ray_trainer.py:956:4-1145:26)
- **ä½ç½®**ï¼š[ray_trainer.py](cci:7://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/ray_trainer.py:0:0-0:0)
- **ä½œç”¨**ï¼šä¸»è®­ç»ƒå¾ªç¯ï¼Œåè°ƒå„ä¸ªè®­ç»ƒé˜¶æ®µ
- **æµç¨‹**ï¼šåŠ è½½checkpoint â†’ éªŒè¯ â†’ è®­ç»ƒå¾ªç¯ â†’ ä¿å­˜

### 2. [actor_rollout_wg.generate_sequences()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/fsdp_workers.py:1770:4-1850:27)
- **ä½ç½®**ï¼š[fsdp_workers.py](cci:7://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/fsdp_workers.py:0:0-0:0)
- **ä½œç”¨**ï¼šä½¿ç”¨VLLMç”Ÿæˆå¤šä¸ªå“åº”
- **é…ç½®**ï¼štemperature=0.8, n=8, tensor_parallel=2

### 3. [actor_rollout_wg.update_actor()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/fsdp_workers.py:601:4-643:21)
- **ä½ç½®**ï¼š[fsdp_workers.py](cci:7://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/fsdp_workers.py:0:0-0:0)
- **ä½œç”¨**ï¼šè°ƒç”¨actorçš„update_policyè¿›è¡Œè®­ç»ƒ
- **åŠŸèƒ½**ï¼šç®¡ç†æ¨¡å‹åŠ è½½/å¸è½½ã€è®¡ç®—æ€§èƒ½æŒ‡æ ‡

### 4. [actor.update_policy()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/actor/dp_actor.py:387:4-513:22)
- **ä½ç½®**ï¼š[dp_actor.py](cci:7://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/workers/actor/dp_actor.py:0:0-0:0)
- **ä½œç”¨**ï¼šæ‰§è¡Œå®é™…çš„å‚æ•°æ›´æ–°
- **æµç¨‹**ï¼šæ•°æ®åˆ†æ‰¹ â†’ å‰å‘ä¼ æ’­ â†’ æŸå¤±è®¡ç®— â†’ åå‘ä¼ æ’­

### 5. [compute_sft_loss()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/core_algos.py:634:0-641:18)
- **ä½ç½®**ï¼š[core_algos.py](cci:7://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/core_algos.py:0:0-0:0)
- **ä½œç”¨**ï¼šè®¡ç®—ç›‘ç£å¾®è°ƒæŸå¤±
- **å…¬å¼**ï¼š`-mean(log_prob * mask)`

### 6. [compute_response_mask()](cci:1://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/ray_trainer.py:182:0-203:51)
- **ä½ç½®**ï¼š[ray_trainer.py](cci:7://file:///d:/%E5%B7%A5%E4%BD%9C%E6%96%87%E4%BB%B6/RAG%E5%BC%80%E5%8F%91/Query_RL/Program/OPD/LMOps/gad/verl/verl/trainer/ppo/ray_trainer.py:0:0-0:0)
- **ä½œç”¨**ï¼šæå–å“åº”éƒ¨åˆ†çš„attention mask
- **ç”¨é€”**ï¼šç¡®ä¿åªè®¡ç®—å“åº”tokençš„æŸå¤±

## äº”ã€é…ç½®å‚æ•°è§£æ

### æ ¸å¿ƒé…ç½®
```yaml
algorithm:
  adv_estimator: grpo          # ä½¿ç”¨GRPOæ¡†æ¶ï¼ˆä½†ä¸ç”¨å…¶ä¼˜åŠ¿è®¡ç®—ï¼‰

data:
  train_batch_size: 256        # 32 prompts Ã— 8 = 256
  max_prompt_length: 2048
  max_response_length: 1536

actor:
  lr: 5e-6                     # å­¦ä¹ ç‡
  grad_clip: 0.2               # æ¢¯åº¦è£å‰ª
  ppo_mini_batch_size: 256     # mini-batchå¤§å°
  use_dynamic_bsz: True        # åŠ¨æ€æ‰¹å¤„ç†
  ppo_max_token_len_per_gpu: 20480

rollout:
  name: vllm                   # ä½¿ç”¨VLLMå¼•æ“
  temperature: 0.8             # é‡‡æ ·æ¸©åº¦
  n: 8                         # æ¯ä¸ªpromptç”Ÿæˆ8ä¸ªå“åº”
  tensor_model_parallel_size: 2

trainer:
  total_epochs: 4
  save_freq: 50
  test_freq: 50
  critic_warmup: 10            # å‰10æ­¥ä¸æ›´æ–°actor
```

## å…­ã€æ•°æ®æµç¤ºæ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: æ•°æ®åŠ è½½                                         â”‚
â”‚ Input: 32 prompts + 32 teacher_responses                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: VLLMç”Ÿæˆ (n=8)                                  â”‚
â”‚ Output: 256 responses (32Ã—8)                            â”‚
â”‚ ç”¨é€”: ç›‘æ§è´¨é‡ï¼Œä¸å‚ä¸è®­ç»ƒ                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: æ•°æ®æ‰©å±•                                         â”‚
â”‚ batch = batch.repeat(n=8)                               â”‚
â”‚ ç»“æœ: 256ä¸ªæ ·æœ¬ï¼ˆåŒ…å«responseså’Œteacher_responseï¼‰        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: é€‰æ‹©teacheræ•°æ®                                  â”‚
â”‚ select_keys = ["teacher_response", ...]                â”‚
â”‚ âš ï¸ å…³é”®: ä¸¢å¼ƒ8ä¸ªé‡‡æ ·çš„responses                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: SFTè®­ç»ƒ                                          â”‚
â”‚ Loss = -mean(log P(teacher_response))                   â”‚
â”‚ ç›®æ ‡: è®©æ¨¡å‹å­¦ä¼šç”Ÿæˆteacherçš„å“åº”                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ä¸ƒã€ä¸æ ‡å‡†GRPOçš„å¯¹æ¯”

| ç‰¹æ€§ | SeqKD (æœ¬å®ç°) | æ ‡å‡†GRPO |
|------|---------------|----------|
| **ç”Ÿæˆå“åº”æ•°** | 8ä¸ª | 8ä¸ª |
| **å¥–åŠ±è®¡ç®—** | Rouge-Lï¼ˆä»…ç›‘æ§ï¼‰ | ç”¨äºä¼˜åŠ¿è®¡ç®— |
| **ä¼˜åŠ¿ä¼°è®¡** | âŒ ä¸ä½¿ç”¨ | âœ… ç»„å†…ç›¸å¯¹ä¼˜åŠ¿ |
| **è®­ç»ƒæ•°æ®** | åªç”¨teacher | ä½¿ç”¨8ä¸ªé‡‡æ · |
| **æŸå¤±å‡½æ•°** | SFTæŸå¤± | ç­–ç•¥æ¢¯åº¦æŸå¤± |
| **è®­ç»ƒç›®æ ‡** | æ¨¡ä»¿teacher | æœ€å¤§åŒ–ç›¸å¯¹ä¼˜åŠ¿ |

## å…«ã€ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

### 1. æ¸è¿›å¼è®­ç»ƒç­–ç•¥
```
Stage 0 (SeqKD) â†’ Stage 1 (Warmup) â†’ Stage 2 (GAD)
   ç¨³å®šåŸºçº¿          è®­ç»ƒåˆ¤åˆ«å™¨        å¯¹æŠ—è®­ç»ƒ
```

### 2. åŸºç¡€è®¾æ–½å‡†å¤‡
- GRPOæ¡†æ¶æ”¯æŒå¤šå“åº”ç”Ÿæˆ
- ä¸ºåç»­GADè®­ç»ƒæä¾›ç»Ÿä¸€æ¥å£
- ä»£ç å¤ç”¨ï¼Œé™ä½ç»´æŠ¤æˆæœ¬

### 3. è´¨é‡ç›‘æ§
- Rouge-Låˆ†æ•°è¿½è¸ªè®­ç»ƒè¿›åº¦
- éªŒè¯æ¨¡å‹æ˜¯å¦å­¦ä¹ åˆ°æ­£ç¡®æ¨¡å¼
- ä¸ºè¶…å‚æ•°è°ƒä¼˜æä¾›ä¾æ®

## ä¹ã€è¾“å‡ºä¸æ£€æŸ¥ç‚¹

### ä¿å­˜å†…å®¹
```
/tmp/${EXP_NAME}/
â”œâ”€â”€ global_step_50/
â”‚   â”œâ”€â”€ actor/              # Actoræ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ data.pt             # DataLoaderçŠ¶æ€
â”‚   â””â”€â”€ ...
â”œâ”€â”€ global_step_100/
â””â”€â”€ latest_checkpointed_iteration.txt
```

### æ—¥å¿—æŒ‡æ ‡
- `actor/pg_loss`: SFTæŸå¤±
- `actor/teacher_pg_loss`: TeacheræŸå¤±ï¼ˆåŒä¸Šï¼‰
- `actor/lr`: å½“å‰å­¦ä¹ ç‡
- `actor/grad_norm`: æ¢¯åº¦èŒƒæ•°
- `val/rouge-L/mean`: éªŒè¯é›†Rouge-Låˆ†æ•°

## åã€æ€»ç»“

SeqKDé˜¶æ®µæ˜¯ä¸€ä¸ª**ä½¿ç”¨GRPOåŸºç¡€è®¾æ–½çš„çº¯SFTè®­ç»ƒ**ï¼š

âœ… **åšäº†ä»€ä¹ˆ**ï¼š
- ç”Ÿæˆå¤šä¸ªå“åº”ç”¨äºè´¨é‡è¯„ä¼°
- ä½¿ç”¨teacherå“åº”è¿›è¡Œç›‘ç£è®­ç»ƒ
- ä¸ºåç»­å¯¹æŠ—è®­ç»ƒå‡†å¤‡æ¨¡å‹

âŒ **æ²¡åšä»€ä¹ˆ**ï¼š
- ä¸ä½¿ç”¨GRPOçš„ä¼˜åŠ¿è®¡ç®—
- ä¸ä½¿ç”¨8ä¸ªé‡‡æ ·ç»“æœè®­ç»ƒ
- ä¸è¿›è¡Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–

ğŸ¯ **ç›®çš„**ï¼š
- æä¾›æ€§èƒ½baseline
- è®­ç»ƒç¨³å®šçš„åˆå§‹æ¨¡å‹
- ä¸ºGADå¯¹æŠ—è®­ç»ƒæ‰“åŸºç¡€