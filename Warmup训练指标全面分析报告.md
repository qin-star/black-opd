# Warmup 训练指标全面分析报告

## 分析日期
2026-01-29

## 数据来源
`tensorboard/1-29-warmup/events.out.tfevents.1769656891.ubuntu.1296875.0`

---

## 1. d_acc 变化趋势分析 🚨

### 关键数据

| Step | d_acc | 变化 |
|------|-------|------|
| 1 | 64.84% | - |
| 2 | 95.21% | +30.37% |
| 3 | 95.99% | +0.78% |
| 4 | 98.24% | +2.25% |
| 5 | 99.41% | +1.17% |
| 6 | 98.44% | -0.97% |
| 7 | 97.46% | -0.98% |
| 8 | 98.63% | +1.17% |
| 9 | 98.44% | -0.19% |
| 10 | 97.17% | -1.27% |

### 🚨 严重问题：d_acc 上升过快

**Step 1 → Step 2**: 从 64.84% 暴涨到 95.21%（+30.37%）

**分析**:
- Step 1 的 64.84% 是完美的起点（在目标范围 65-85%）
- Step 2 就达到 95.21%，说明模型**几乎立即学会了区分 Teacher 和 Student**
- 从 Step 2 开始，d_acc 一直保持在 95-99% 之间

**可能原因**:

1. **数据质量问题（最可能）**:
   ```
   数据中 Teacher 确实远优于 Student
   → 模型很容易学会区分
   → d_acc 快速上升到 95%+
   ```

2. **长度偏见（需要验证）**:
   ```
   Teacher 平均长度: 177 tokens
   Student 平均长度: 197 tokens
   → 模型学到"短=好"的模式
   → 快速达到高 d_acc
   ```

3. **EOS Token 问题（已发现）**:
   ```
   Student 含 EOS，Teacher 不含 EOS
   → 平均值计算不一致
   → 导致分数差异
   ```

### 建议

1. **立即修复 EOS Token 问题**（已完成）
2. **重新训练并观察 d_acc 是否仍然快速上升**
3. **如果仍然快速上升 → 数据质量问题，需要数据增强**

---

## 2. score_diff 变化分析 ✅

### 关键数据

| Step | score_diff | Teacher 均值 | Student 均值 | 实际差值 |
|------|-----------|-------------|-------------|---------|
| 1 | 0.32 | 1.24 | 1.03 | 0.21 |
| 2 | 1.33 | 1.49 | 0.43 | 1.06 |
| 3 | 1.56 | 1.83 | -0.12 | 1.95 |
| 4 | 1.60 | 1.46 | -0.72 | 2.18 |
| 5 | 1.68 | 1.31 | -0.94 | 2.25 |
| 6 | 1.68 | 1.08 | -1.12 | 2.20 |
| 7 | 1.64 | 1.00 | -0.90 | 1.90 |
| 8 | 1.74 | 1.04 | -0.85 | 1.89 |
| 9 | 1.62 | 0.96 | -0.64 | 1.60 |
| 10 | 1.73 | 1.04 | -0.67 | 1.71 |

### ✅ score_diff 在合理范围

**平均 score_diff**: ~1.6（在目标范围 1-3）

**观察**:
- Step 1: 0.32（非常小，因为模型刚开始训练）
- Step 2-10: 稳定在 1.3-1.7 之间
- 没有出现过大或过小的异常值

### ⚠️  Student 分数持续下降

**趋势**:
- Step 1: 1.03 → Step 10: -0.67
- 下降了 1.70

**问题**:
- Student 分数从正数变成负数
- 说明模型认为 Student 的回答质量在下降
- 可能是学到了错误的模式（如长度偏见）

---

## 3. 长度偏见分析 🚨

### 关键数据

| Step | 长度-奖励相关系数 |
|------|-----------------|
| 10 | -0.262 |
| 20 | -0.322 |
| 30 | -0.325 |
| 40 | -0.164 |
| 50 | -0.141 |
| 60 | -0.125 |
| 70 | -0.184 |

### 🚨 存在显著长度偏见

**平均相关系数**: -0.217

**含义**:
- 负相关系数 → 长度越长，分数越低
- |-0.217| > 0.15 → 存在显著长度偏见
- Step 20-30 最严重（-0.32）

**验证**:
```
Teacher 平均长度: 177 tokens → 平均分: 1.24
Student 平均长度: 197 tokens → 平均分: 1.03 → -0.67

长度差异: 20 tokens (11%)
分数差异: 1.7 (从 1.03 降到 -0.67)
```

### 🔍 长度偏见的证据

1. **Step 2-10 的数据**:
   ```
   Teacher 更短 (177 vs 197) → 分数更高 (1.24 vs 1.03)
   Student 更长 → 分数持续下降 (1.03 → -0.67)
   ```

2. **相关系数持续为负**:
   ```
   所有测量点都是负相关
   说明模型一直在学习"短=好"的模式
   ```

3. **d_acc 快速上升**:
   ```
   模型可能通过长度快速区分 Teacher 和 Student
   → d_acc 从 64% 跳到 95%
   ```

### 建议

**调整 raw_weight 和 norm_weight**:
```python
# 当前配置
raw_weight = 0.7  # 原始分数权重
norm_weight = 0.3  # 长度归一化分数权重

# 建议配置
raw_weight = 0.5  # 降低原始分数权重
norm_weight = 0.5  # 增大归一化权重

# 原理：
# - 原始分数可能包含长度偏见
# - 归一化分数会除以长度，减少长度影响
# - 增大 norm_weight 可以缓解长度偏见
```

---

## 4. 梯度健康度分析 ⚠️

### 关键数据

| Step | grad_norm | grad_norm_before_clip |
|------|-----------|----------------------|
| 1 | 2.31 | 2.31 |
| 2 | 1.61 | 1.61 |
| 3 | 1.06 | 1.06 |
| 4 | 0.76 | 0.76 |
| 5 | **39.18** | **39.18** |
| 6 | 3.65 | 3.65 |
| 7 | 1.43 | 1.43 |
| 8 | 1.29 | 1.29 |
| 9 | 1.78 | 1.78 |
| 10 | 0.73 | 0.73 |

### ⚠️  Step 5 出现梯度爆炸

**Step 5 梯度**: 39.18（远超正常范围 0.5-5.0）

**分析**:
- Step 1-4: 梯度正常下降（2.31 → 0.76）
- Step 5: 突然爆炸到 39.18
- Step 6: 恢复到 3.65
- Step 7-10: 继续正常

**可能原因**:
1. **某个 batch 的数据异常**（最可能）
2. **学习率过大**（但 lr=1e-5 应该不会）
3. **数值不稳定**（BFloat16 精度问题）

**影响**:
- 梯度裁剪（grad_clip=40）起作用了
- 没有导致训练崩溃
- 但可能影响了该步的学习

### 建议

1. **检查 Step 5 的训练日志**，看是否有异常数据
2. **如果频繁出现，考虑降低学习率**
3. **当前梯度裁剪（40）是合理的**

---

## 5. 分数分布演变分析 🚨

### Teacher 分数演变

| Step | 均值 | 标准差 | 范围 |
|------|------|--------|------|
| 1 | 1.24 | 0.80 | [0.44, 2.04] |
| 5 | 1.31 | 0.94 | [0.37, 2.25] |
| 10 | 1.04 | 0.59 | [0.45, 1.63] |

**趋势**: 相对稳定，略有下降

### Student 分数演变

| Step | 均值 | 标准差 | 范围 |
|------|------|--------|------|
| 1 | 1.03 | 0.88 | [0.15, 1.91] |
| 5 | -0.94 | 1.02 | [-1.96, 0.08] |
| 10 | -0.67 | 0.72 | [-1.39, 0.05] |

**趋势**: 🚨 **快速下降**

### 🚨 严重问题：Student 分数崩溃

**Step 1 → Step 10**:
- Student: 1.03 → -0.67（下降 1.70）
- Teacher: 1.24 → 1.04（下降 0.20）

**分析**:
- Student 分数下降速度远超 Teacher
- 说明模型认为 Student 的回答质量在快速恶化
- 这是**不合理的**，因为 Student 的回答内容没有变化

**可能原因**:
1. **长度偏见**: Student 更长 → 分数更低
2. **EOS Token 问题**: Student 含 EOS → 平均值被拉低
3. **模型过拟合**: 学到了错误的区分模式

---

## 6. 难样本比例分析 🚨

### 关键数据

| Step | 难样本比例 (score_diff < 0.1) |
|------|------------------------------|
| 1 | 17.19% |
| 2 | 3.71% |
| 3 | 3.32% |
| 4 | 2.25% |
| 5 | 1.17% |
| 6 | 1.76% |
| 7 | 1.07% |
| 8 | 0.88% |
| 9 | 1.66% |
| 10 | 2.15% |

### 🚨 难样本急剧减少

**Step 1 → Step 10**: 17.19% → 2.15%（下降 15%）

**含义**:
- Step 1: 17% 的样本 Teacher 和 Student 分数接近（难以区分）
- Step 10: 只有 2% 的样本难以区分
- 说明模型变得**过度自信**

**问题**:
- 难样本过少（< 5%）说明模型区分过于简单
- 可能是学到了简单的模式（如长度）而非真正的质量

---

## 7. EOS Token 问题的影响 🚨

### 发现的问题

**案例 1**: "人类基因组" vs "人类的基因组"
```
Student: [103971, 102477, 40027, 151645]  # 含 EOS
         平均值 = (v1 + v2 + v3 + v_eos) / 4
         Score: -0.19

Teacher: [103971, 9370, 102477, 40027]     # 不含 EOS
         平均值 = (v1 + v2 + v3 + v4) / 4
         Score: 0.42

分差: 0.61（语义近似，但分差大）
```

**案例 2**: "无性别偏向"（完全相同文本）
```
Student: [42192, 109391, 115673, 151645]  # 含 EOS
         平均值 = (v1 + v2 + v3 + v_eos) / 4
         Score: -0.62

Teacher: [42192, 109391, 115673]           # 不含 EOS
         平均值 = (v1 + v2 + v3) / 3
         Score: -1.02

分差: 0.40（相同文本，但分差大！）
```

### 根本原因

```python
# 问题：response_mask 包含 EOS token
response_mask = attention_mask[:, -response_length:]
# 对于 Student: [1, 1, 1, 1]  # EOS 位置也是 1
# 对于 Teacher: [1, 1, 1]     # 没有 EOS

# 计算平均值
values_sum = (values * response_mask).sum()
values_count = response_mask.sum()
avg = values_sum / values_count

# 结果：
# Student: 包含 EOS token 的 value
# Teacher: 不包含 EOS token
# → 即使文本相同，平均值也不同！
```

### 影响评估

1. **相同文本分差**: 0.40（应该 < 0.1）
2. **近似语义分差**: 0.61（过大）
3. **Student 分数下降**: 可能部分由 EOS token 导致

### 修复方案（已实施）

```python
# 显式排除 EOS token
is_eos = (response_ids == eos_token_id)
response_mask_no_eos = response_mask & (~is_eos)

# 使用排除 EOS 的 mask 计算平均值
values_sum = (values * response_mask_no_eos).sum()
values_count = response_mask_no_eos.sum().clamp(min=1)
sequence_value = values_sum / values_count
```

---

## 总结与建议

### 🚨 发现的主要问题

1. **d_acc 上升过快**
   - Step 1 (64.84%) → Step 2 (95.21%)
   - 说明数据质量问题或长度偏见

2. **存在显著长度偏见**
   - 长度-奖励相关系数: -0.217
   - 长度越长，分数越低

3. **EOS Token 导致分数不一致**
   - 相同文本分差: 0.40
   - 已修复，需要重新训练验证

4. **Student 分数快速下降**
   - Step 1 (1.03) → Step 10 (-0.67)
   - 可能是长度偏见 + EOS Token 问题

5. **难样本过少**
   - Step 10 只有 2.15%
   - 模型过度自信

6. **Step 5 梯度爆炸**
   - grad_norm = 39.18
   - 需要检查该步的数据

### 📋 立即行动

1. **✅ 已修复 EOS Token 问题**
   - 显式排除 EOS token
   - 确保相同文本得到相同分数

2. **🔧 调整 raw_weight/norm_weight**
   ```python
   # verl/verl/trainer/ppo/core_algos.py
   # 当前: raw_weight=0.7, norm_weight=0.3
   # 建议: raw_weight=0.5, norm_weight=0.5
   ```

3. **🔧 增大 temperature**
   ```python
   # verl/verl/workers/critic/dp_critic.py, line 747
   # 当前: temperature=5.0
   # 建议: temperature=10.0
   ```

4. **🔄 重新训练 Warmup**
   ```bash
   # 清理旧 checkpoint
   rm -rf outputs/warmup_checkpoints/*
   
   # 重新训练
   bash scripts/train/A3b_gspo/content_merge_trainning/A3b-warmup-gspo-optimized.sh
   ```

### 📊 重新训练后的监控指标

**期望改进**:

1. **d_acc**:
   - 当前: Step 2 就达到 95%
   - 期望: 逐渐上升，Step 10 在 75-85%

2. **相同文本分差**:
   - 当前: 0.40
   - 期望: < 0.1

3. **长度-奖励相关系数**:
   - 当前: -0.217
   - 期望: < 0.15

4. **Student 分数**:
   - 当前: 1.03 → -0.67（下降 1.70）
   - 期望: 相对稳定，不应大幅下降

5. **难样本比例**:
   - 当前: 2.15%
   - 期望: 5-15%

### 🎯 成功标准

**修复成功的标志**:
- ✅ 相同文本分差 < 0.1
- ✅ d_acc 在 Step 10 时 < 85%
- ✅ 长度相关系数 < 0.15
- ✅ Student 分数不会快速下降
- ✅ 难样本比例 > 5%

**如果仍有问题**:
- 考虑数据增强（添加长度多样性）
- 考虑添加长度惩罚项
- 考虑调整训练策略

---

**分析日期**: 2026-01-29
**分析者**: AI Assistant
**状态**: 🚨 发现多个严重问题，已提供修复方案
**下一步**: 重新训练并验证修复效果
