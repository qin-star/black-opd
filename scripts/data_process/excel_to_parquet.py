#!/usr/bin/env python3
"""
å°† core_content è®­ç»ƒæ•°æ®è½¬æ¢ä¸º GAD è®­ç»ƒæ‰€éœ€çš„ parquet æ ¼å¼
excelåˆ†ä¸ºä¸¤åˆ—ï¼šprompt || teacher_response

è¾“å…¥ï¼šcore_content_trainning_data.xlsx
è¾“å‡ºï¼šè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„Excelå’Œparquetæ–‡ä»¶ï¼ˆ2:8æ¯”ä¾‹åˆ‡åˆ†ï¼‰train_ratio å¯è°ƒ
"""

import pandas as pd
import json
import os
import random
from typing import List, Dict, Tuple


def convert_row(row: pd.Series) -> Dict:
    """
    è½¬æ¢å•è¡Œæ•°æ®
    
    Args:
        row: Excel ä¸­çš„ä¸€è¡Œæ•°æ®
        
    Returns:
        è½¬æ¢åçš„å­—å…¸ï¼ŒåŒ…å« content å’Œ teacher_response
    """
    # ç›´æ¥ä»ç¬¬ä¸€åˆ—è·å– prompt
    prompt = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
    
    # ç›´æ¥ä»ç¬¬äºŒåˆ—è·å– teacher_response
    teacher_response = str(row.iloc[1]) if pd.notna(row.iloc[1]) else ""
    
    # æ„é€  contentï¼ˆæ¶ˆæ¯åˆ—è¡¨æ ¼å¼ï¼‰
    content = [
        {
            "content": prompt,
            "role": "user"
        }
    ]
    
    return {
        "content": content,
        "teacher_response": teacher_response
    }


def split_dataset(df: pd.DataFrame, train_ratio: float = 0.9, random_seed: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    éšæœºåˆ‡åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    
    Args:
        df: åŸå§‹æ•°æ®æ¡†
        train_ratio: è®­ç»ƒé›†æ¯”ä¾‹ï¼Œé»˜è®¤0.8ï¼ˆå³2:8çš„æµ‹è¯•é›†:è®­ç»ƒé›†æ¯”ä¾‹ï¼‰
        random_seed: éšæœºç§å­ï¼Œç¡®ä¿å¯é‡ç°æ€§
        
    Returns:
        è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ•°æ®æ¡†å…ƒç»„ (train_df, test_df)
    """
    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    random.seed(random_seed)
    
    # éšæœºæ‰“ä¹±æ•°æ®
    shuffled_df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)
    
    # è®¡ç®—åˆ‡åˆ†ç‚¹
    split_idx = int(len(shuffled_df) * train_ratio)
    
    # åˆ‡åˆ†æ•°æ®
    train_df = shuffled_df.iloc[:split_idx].reset_index(drop=True)
    test_df = shuffled_df.iloc[split_idx:].reset_index(drop=True)
    
    return train_df, test_df


def save_dataset(df: pd.DataFrame, output_dir: str, base_name: str, dataset_type: str) -> Tuple[str, str]:
    """
    ä¿å­˜æ•°æ®é›†ä¸ºExcelå’ŒParquetæ ¼å¼
    
    Args:
        df: è¦ä¿å­˜çš„æ•°æ®æ¡†
        output_dir: è¾“å‡ºç›®å½•
        base_name: åŸºç¡€æ–‡ä»¶å
        dataset_type: æ•°æ®é›†ç±»å‹ï¼ˆtrain/testï¼‰
        
    Returns:
        Excelæ–‡ä»¶å’ŒParquetæ–‡ä»¶çš„è·¯å¾„å…ƒç»„
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # æ„é€ æ–‡ä»¶å
    excel_filename = f"{base_name}_{dataset_type}.xlsx"
    parquet_filename = f"{base_name}_{dataset_type}.parquet"
    
    excel_path = os.path.join(output_dir, excel_filename)
    parquet_path = os.path.join(output_dir, parquet_filename)
    
    # ä¿å­˜Excelæ–‡ä»¶ï¼ˆä¿å­˜åŸå§‹æ ¼å¼ï¼‰
    df.to_excel(excel_path, index=False)
    
    # è½¬æ¢å¹¶ä¿å­˜ä¸ºParquetæ ¼å¼
    converted_data = []
    for idx, row in df.iterrows():
        try:
            converted_row = convert_row(row)
            converted_data.append(converted_row)
        except Exception as e:
            print(f"   âš ï¸  ç¬¬ {idx} è¡Œè½¬æ¢å¤±è´¥: {e}")
            continue
    
    # åˆ›å»ºè½¬æ¢åçš„DataFrame
    result_df = pd.DataFrame(converted_data)
    
    # æ·»åŠ idåˆ—
    result_df['id'] = [f"{base_name}_{dataset_type}_{i:06d}" for i in range(len(result_df))]
    
    # è°ƒæ•´åˆ—é¡ºåº
    result_df = result_df[['id', 'content', 'teacher_response']]
    
    # ä¿å­˜Parquetæ–‡ä»¶
    result_df.to_parquet(parquet_path, index=False)
    
    return excel_path, parquet_path


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("Core Content Excel æ•°æ®è½¬æ¢ä¸º GAD Parquet æ ¼å¼")
    print("=" * 60)
    
    print("=" * 60)
    print("Core Content Excel æ•°æ®è½¬æ¢ä¸º GAD Parquet æ ¼å¼ï¼ˆæ”¯æŒè®­ç»ƒé›†/æµ‹è¯•é›†åˆ‡åˆ†ï¼‰")
    print("=" * 60)
    
    # 1. è·å–è¾“å…¥æ–‡ä»¶è·¯å¾„
    excel_path = "/home/jovyan/JQ/gad_gspo_B300/scripts/data_process/trainning_data/semantic_understanding/semantic_understanding_1224.xlsx"
    
    if not os.path.exists(excel_path):
        print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
        return
    
    # 2. ç¡®å®šè¾“å‡ºç›®å½•ï¼ˆä¸è¾“å…¥ExcelåŒç›®å½•ä¸‹çš„processedæ–‡ä»¶å¤¹ï¼‰
    excel_dir = os.path.dirname(excel_path)
    output_dir = os.path.join(excel_dir, "processed")
    
    # 3. è·å–åŸºç¡€æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    base_name = os.path.splitext(os.path.basename(excel_path))[0]
    
    print(f"\nğŸ“– è¯»å– Excel: {excel_path}")
    df = pd.read_excel(excel_path)
    print(f"   âœ… è¯»å–æˆåŠŸï¼Œå…± {len(df)} è¡Œ")
    print(f"   åˆ—å: {df.columns.tolist()}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    
    # 4. åˆ‡åˆ†æ•°æ®é›†
    print(f"\nğŸ”„ åˆ‡åˆ†æ•°æ®é›†ï¼ˆè®­ç»ƒé›†:æµ‹è¯•é›† = 9:1ï¼‰...")
    train_df, test_df = split_dataset(df, train_ratio=0.99, random_seed=42)
    print(f"   âœ… åˆ‡åˆ†å®Œæˆ")
    print(f"   è®­ç»ƒé›†: {len(train_df)} è¡Œ ({len(train_df)/len(df)*100:.1f}%)")
    print(f"   æµ‹è¯•é›†: {len(test_df)} è¡Œ ({len(test_df)/len(df)*100:.1f}%)")
    
    # 5. ä¿å­˜è®­ç»ƒé›†
    print(f"\nğŸ’¾ ä¿å­˜è®­ç»ƒé›†...")
    train_excel_path, train_parquet_path = save_dataset(train_df, output_dir, base_name, "train")
    print(f"   âœ… è®­ç»ƒé›†ä¿å­˜æˆåŠŸ")
    print(f"   Excel: {train_excel_path}")
    print(f"   Parquet: {train_parquet_path}")
    
    # 6. ä¿å­˜æµ‹è¯•é›†
    print(f"\nğŸ’¾ ä¿å­˜æµ‹è¯•é›†...")
    test_excel_path, test_parquet_path = save_dataset(test_df, output_dir, base_name, "test")
    print(f"   âœ… æµ‹è¯•é›†ä¿å­˜æˆåŠŸ")
    print(f"   Excel: {test_excel_path}")
    print(f"   Parquet: {test_parquet_path}")
    
    # 7. éªŒè¯è¾“å‡ºæ–‡ä»¶
    print(f"\nğŸ” éªŒè¯è¾“å‡ºæ–‡ä»¶...")
    
    # éªŒè¯è®­ç»ƒé›†Parquet
    try:
        verify_train = pd.read_parquet(train_parquet_path)
        print(f"   è®­ç»ƒé›†Parquet: {len(verify_train)} è¡Œï¼Œåˆ—: {verify_train.columns.tolist()}")
    except Exception as e:
        print(f"   âš ï¸  è®­ç»ƒé›†ParquetéªŒè¯å¤±è´¥: {e}")
    
    # éªŒè¯æµ‹è¯•é›†Parquet
    try:
        verify_test = pd.read_parquet(test_parquet_path)
        print(f"   æµ‹è¯•é›†Parquet: {len(verify_test)} è¡Œï¼Œåˆ—: {verify_test.columns.tolist()}")
    except Exception as e:
        print(f"   âš ï¸  æµ‹è¯•é›†ParquetéªŒè¯å¤±è´¥: {e}")
    
    # 8. æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
    if len(verify_train) > 0:
        print(f"\nğŸ“ è®­ç»ƒé›†ç¬¬ä¸€è¡Œç¤ºä¾‹:")
        first_row = verify_train.iloc[0]
        print(f"   ID: {first_row['id']}")
        print(f"   Content (å‰ 200 å­—ç¬¦): {str(first_row['content'])[:200]}...")
        print(f"   Teacher Response (å‰ 200 å­—ç¬¦): {str(first_row['teacher_response'])[:200]}...")
    
    if len(verify_test) > 0:
        print(f"\nğŸ“ æµ‹è¯•é›†ç¬¬ä¸€è¡Œç¤ºä¾‹:")
        first_row = verify_test.iloc[0]
        print(f"   ID: {first_row['id']}")
        print(f"   Content (å‰ 200 å­—ç¬¦): {str(first_row['content'])[:200]}...")
        print(f"   Teacher Response (å‰ 200 å­—ç¬¦): {str(first_row['teacher_response'])[:200]}...")
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®é›†åˆ‡åˆ†å’Œè½¬æ¢å®Œæˆï¼")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - {os.path.basename(train_excel_path)} (è®­ç»ƒé›†Excel)")
    print(f"  - {os.path.basename(train_parquet_path)} (è®­ç»ƒé›†Parquet)")
    print(f"  - {os.path.basename(test_excel_path)} (æµ‹è¯•é›†Excel)")
    print(f"  - {os.path.basename(test_parquet_path)} (æµ‹è¯•é›†Parquet)")
    print("=" * 60)


if __name__ == "__main__":
    main()